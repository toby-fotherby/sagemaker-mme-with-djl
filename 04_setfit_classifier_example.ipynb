{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe6d72e-9f44-4add-85a6-3b6494e39974",
   "metadata": {},
   "source": [
    "# Package Huggingface Setfit Model for SageMaker MME with DJL\n",
    "Example 4: Train, evaluate, and package a setfit sentence classification model for deployment on a SageMaker Multi-Model Endpoint with DJL \n",
    "\n",
    "* This is was tested with an AWS SageMaker conda_pytorch_p310 kernal\n",
    "* This will run best on an instance with a GPU such as an ml.g4dn.xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972e049-efdd-4b8f-9a8d-2226973efebb",
   "metadata": {},
   "source": [
    "Read in essential static variables used across notebooks from the store. These values are set in notebook 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e310b-faf8-445e-ad94-191ab2f3885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e718c6-ce43-40af-9f32-eb960ededb0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install setfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe8ec9-4544-48a7-b60f-2fbbb4b5cbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c82b01-a068-49c3-bcf0-edd158e910fb",
   "metadata": {},
   "source": [
    "## Step 1: Define and train the example model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9dc13-bb05-479c-837e-08d9b4a7ffbf",
   "metadata": {},
   "source": [
    "Leverage an open source sentiment analysis dataset for the example training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1f225-c67a-4b46-ad37-d4e52560f187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "dataset = load_dataset(\"SetFit/sst2\")\n",
    "train_dataset = sample_dataset(dataset[\"train\"], label_column=\"label\", num_samples=8)\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b6be13-15dd-4039-a891-5eb5896318d9",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06008955-0a64-4cda-b857-9f9ee5756550",
   "metadata": {},
   "source": [
    "Here we're utilizing the BAAI/bge-small-en-v1.5 model as the base model, and setting up the labelled output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949e159-375d-4d93-bbf7-9ab930a52562",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing a new SetFit model\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\", labels=[\"negative\", \"positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2134f-4b18-46fc-8c73-a7f481cc54ae",
   "metadata": {},
   "source": [
    "Configure the trainer. \n",
    "\n",
    "These training parameters are enough to demonstrate training, however, not enough for 90%+ accuracy. The intention here being to show the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e4ccc-f490-4b60-939b-088742a2764e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the training arguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    batch_size=32,\n",
    "    num_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eed55a-0940-416b-9e3d-7e8bd0700f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bd7aa-65a7-4d4f-ae3b-8f4d494cf4aa",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4c743-50ee-4c63-a5b8-7cda3cd5ed0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# This trains in less than a minute on a ml.g4dn.xlarge (single GPU) instance,\n",
    "# it will take significantly longer on a CPU based instance and may fail\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09380f3f-6719-4130-8ca5-42b6cdff2120",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3c978-ea70-4f90-8410-ebfb99d28cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "metrics = trainer.evaluate(test_dataset)\n",
    "print(metrics)\n",
    "# => {'accuracy': 0.8511806699615596}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afc609-9579-4c78-94ca-242974f99a28",
   "metadata": {},
   "source": [
    "## Step 2: Export the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b65ff3-4cdd-4d07-b6e0-8a83900b5aec",
   "metadata": {},
   "source": [
    "### Make sure we're starting from a known place in the filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5c94a-43df-412f-8706-ba02ee3b02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9f0af-13c0-49d2-9d33-11e9e0f63948",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2e621-0259-492c-9925-74076d3fd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"setfit-bge-small-v1.5-sst2-8-shot\"\n",
    "s3_model_prefix = \"djl-mme-sklearn-examples\"\n",
    "setfit_model_reference_name = \"setfit-classifier.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f299c-ba90-4988-a658-68bd7a7f416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if setfit-classifier directory does not exist then create it\n",
    "\n",
    "target_dir = \"setfit-classifier\"\n",
    "target_path = f\"./models/{target_dir}\"\n",
    "\n",
    "if not os.path.exists(target_path):\n",
    "    os.makedirs(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b678e-31d2-41a4-9224-f442bbc23595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00464adb-fbf5-4209-8c54-30fea1db0a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "model.save_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f338d-cb92-41ef-b7f3-fdcc47ea39b1",
   "metadata": {},
   "source": [
    "### Test the exported model\n",
    "Instantiate a new instance of the model from the saved file and test it with subset of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f551e-e365-4043-9cae-cd37ea40a4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading a trained model\n",
    "model = SetFitModel.from_pretrained(model_id) # Load from a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f79af-f11e-4191-89bc-7b04cd63c0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performing inference\n",
    "preds = model.predict([\n",
    "    \"It's a charming and often affecting journey.\",\n",
    "    \"It's slow -- very, very slow.\",\n",
    "    \"A sometimes tedious film.\",\n",
    "])\n",
    "print(preds)\n",
    "# => [\"positive\", \"negative\", \"negative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115172c-360e-41b5-a686-ca5b4e5da84f",
   "metadata": {},
   "source": [
    "## Step 3: Deep Learning for Java (DJL) artifact creation\n",
    "\n",
    "We now have our model artifact, but we need the following for our DJL Serving Engine\n",
    "\n",
    "model.py: Inference script with custom model loading + pre/processing code\n",
    "\n",
    "requirements.txt: Additional dependencies, in this case we need to install sklearn and numpy\n",
    "\n",
    "serving.properties: Environment variables for DJL Serving, can adjust number of workers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c79520-0f0a-48e2-a61d-12682ec43e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "#!/usr/bin/env python\n",
    "#\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file\n",
    "# except in compliance with the License. A copy of the License is located at\n",
    "#\n",
    "# http://aws.amazon.com/apache2.0/\n",
    "#\n",
    "# or in the \"LICENSE.txt\" file accompanying this file. This file is distributed on an \"AS IS\"\n",
    "# BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express or implied. See the License for\n",
    "# the specific language governing permissions and limitations under the License.\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from setfit import SetFitModel\n",
    "from djl_python import Input\n",
    "from djl_python import Output\n",
    "\n",
    "\n",
    "class SetFitClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, properties: dict):\n",
    "        \"\"\"\n",
    "        Initialize model.\n",
    "        \"\"\"\n",
    "        print(\"SetFitClassifier: initialize: \" + str(os.listdir()))\n",
    "        model_id = \"setfit-bge-small-v1.5-sst2-8-shot\"\n",
    "        if os.path.exists(model_id):\n",
    "            self.model = SetFitModel.from_pretrained(model_id)\n",
    "            print(\"SetFitClassifier: model loaded during initialization\")\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to find {model_id} directory for SetFit Model Loading\")\n",
    "        self.initialized = True\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\"\n",
    "        Custom service entry point function.\n",
    "\n",
    "        :param inputs: the Input object holds a list of numpy array\n",
    "        :return: the Output object to be send back\n",
    "        \"\"\"\n",
    "\n",
    "        # example input: [\"It's a charming and often affecting journey.\", \"It's slow -- very, very slow.\"]\n",
    "        \n",
    "        try:\n",
    "            data = inputs.get_as_json()\n",
    "\n",
    "            res = self.model.predict(data)\n",
    "            outputs = Output()\n",
    "            outputs.add_as_json(res)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # error handling\n",
    "            logging.exception(f\"SetFitClassifier: inference failed: {str(e)}\")\n",
    "            outputs = Output().error(str(e))\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "_service = SetFitClassifier()\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    \"\"\"\n",
    "    Default handler function\n",
    "    \"\"\"\n",
    "    if not _service.initialized:\n",
    "        # stateful model\n",
    "        _service.initialize(inputs.get_properties())\n",
    "    \n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "\n",
    "    return _service.inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d03ab0-dbb5-4fcb-9bcd-625feb4fb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "setfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5179cd0-3f70-462a-9ae0-85ce57f173ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "# idle time in seconds before the worker thread is scaled down, the default is \n",
    "max_idle_time=600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12073927-5eac-4bf4-b828-48b5ce0c088b",
   "metadata": {},
   "source": [
    "### Tarball Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff67f9-be9d-4d7c-b627-f9cfbbbbe10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tar file with model data + inference code, replace this cell with your model.joblib\n",
    "import subprocess\n",
    "\n",
    "bashCommand = f\"tar -cvpzf model.tar.gz {model_id} requirements.txt model.py serving.properties\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d0535-0ca5-4986-95ba-6a504e4d6760",
   "metadata": {},
   "source": [
    "Take a quick look at what's in the tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402e154-833e-462d-8b95-0c1cbbb76de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -tvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8031d7c-af7a-42b8-91ad-95e24bf4ce52",
   "metadata": {},
   "source": [
    "### Upload the tarball to target location on Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73022526-6501-4c92-a9e1-d7bb53d1ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import session as sagemaker_session\n",
    "from boto3 import client as boto3_client\n",
    "\n",
    "sess = sagemaker_session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "s3_client = boto3_client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39805eda-f254-482e-a85c-5d4ba6dd5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the tarball to Amazon S3 where is will be used to back model requests\n",
    "with open(\"model.tar.gz\", \"rb\") as f:\n",
    "    s3_client.upload_fileobj(f,\n",
    "                             bucket,\n",
    "                             f\"{s3_model_prefix}/{setfit_model_reference_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a45fe0-584d-48bb-970b-c72a64a4ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mme_artifacts = \"s3://{}/{}/\".format(bucket, s3_model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f090f-d8bc-450a-9fd1-44bd56b19a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the tar ball is saved to the target location\n",
    "!aws s3 ls {mme_artifacts}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d734b9-186f-42a5-a83f-d073a00ecf2f",
   "metadata": {},
   "source": [
    "## Training and packaging complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
